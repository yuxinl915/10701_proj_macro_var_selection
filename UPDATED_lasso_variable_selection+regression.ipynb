{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuxinl915/10701_proj_macro_var_selection/blob/main/UPDATED_lasso_variable_selection%2Bregression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab7e6298-8aa1-42d1-9e02-a97912fdbd68",
      "metadata": {
        "id": "ab7e6298-8aa1-42d1-9e02-a97912fdbd68",
        "outputId": "73f11ed7-5ae7-497b-f2ec-4f81a178af56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\yimengs\\appdata\\roaming\\python\\python311\\site-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yimengs\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yimengs\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d83b13f8-8f1c-48e6-81c1-e57ccb5d5d54",
      "metadata": {
        "id": "d83b13f8-8f1c-48e6-81c1-e57ccb5d5d54"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fe08321d-e03d-4a63-831b-0d612b00cc24",
      "metadata": {
        "id": "fe08321d-e03d-4a63-831b-0d612b00cc24"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"data.csv.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0004fc80-0204-45e7-8c4a-f35e62b6efd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0004fc80-0204-45e7-8c4a-f35e62b6efd7",
        "outputId": "d7172417-f214-4293-ed23-b3ea389a3752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Firm Characteristics: ['me', 'be_me', 'ope_be', 'at_gr1', 'ret_3_1']\n",
            "Macro Variables: ['TB3MS', 'GS1', 'GS5', 'GS10', 'GS30', 'BAA', 'AAA', 'UNRATE', 'ICSA', 'M2', 'FEDFUNDS', 'VIX', 'OIL', 'INDPRO', 'TCU', 'RPI', 'PAYEMS', 'CPI', 'CPICORE', 'PCEPI', 'term_spread', 'def_spread', 'inflation', 'core_inflation', 'real_ff', 'm2_growth', 'indpro_growth', 'rpi_growth', 'payems_growth', 'oil_ret']\n"
          ]
        }
      ],
      "source": [
        "firm_characteristics = ['me', 'be_me', 'ope_be', 'at_gr1', 'ret_3_1']\n",
        "macro_variables = [col for col in data.columns if col not in firm_characteristics][2:]\n",
        "\n",
        "print(\"Firm Characteristics:\", firm_characteristics)\n",
        "print(\"Macro Variables:\", macro_variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6b1fa005-151b-41ac-bbac-49a1a6bb7536",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1fa005-151b-41ac-bbac-49a1a6bb7536",
        "outputId": "1fef0595-4b77-483c-aba0-8b9b1dcf3b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n",
            "/tmp/ipython-input-3621462998.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data[new_col_name] = data[firm_char] * data[macro_var]\n"
          ]
        }
      ],
      "source": [
        "for firm_char in firm_characteristics:\n",
        "    for macro_var in macro_variables:\n",
        "        new_col_name = f\"{firm_char}_x_{macro_var}\"\n",
        "        data[new_col_name] = data[firm_char] * data[macro_var]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f319212-a103-4183-b986-fb1aa1193e7a",
      "metadata": {
        "id": "2f319212-a103-4183-b986-fb1aa1193e7a"
      },
      "outputs": [],
      "source": [
        "unscale_cols = [\"eom\", \"ret_exc_lead1m\"]\n",
        "scale_cols = [c for c in data.columns if c not in unscale_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c089049-615d-402d-aedf-2c36abccd26c",
      "metadata": {
        "id": "9c089049-615d-402d-aedf-2c36abccd26c",
        "outputId": "2a3ba57a-c248-45e5-bd88-8bfde055640f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Sort by date and reset index so index == row position\n",
        "data = data.sort_values(\"eom\").reset_index(drop=True)\n",
        "\n",
        "# 2. Find the row position where test period begins\n",
        "cutoff_date = \"2020-01-31\"\n",
        "test_idx = data.index[data[\"eom\"] >= cutoff_date][0]  # now this is a position\n",
        "\n",
        "# 3. Build train/test arrays directly from slices (no X_all / y_all)\n",
        "X_train = data.loc[:test_idx-1, scale_cols].to_numpy(dtype=\"float32\")\n",
        "y_train = data.loc[:test_idx-1, \"ret_exc_lead1m\"].to_numpy(dtype=\"float32\")\n",
        "\n",
        "X_test  = data.loc[test_idx:, scale_cols].to_numpy(dtype=\"float32\")\n",
        "y_test  = data.loc[test_idx:, \"ret_exc_lead1m\"].to_numpy(dtype=\"float32\")\n",
        "\n",
        "# 4. Free the big DataFrame as soon as we're done with it\n",
        "del data\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d23597f-7972-4c7c-abb0-9aaa504f3715",
      "metadata": {
        "id": "7d23597f-7972-4c7c-abb0-9aaa504f3715"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb5e7fc0-662a-453b-bec2-ecfebb3c008e",
      "metadata": {
        "id": "bb5e7fc0-662a-453b-bec2-ecfebb3c008e",
        "outputId": "ca383619-65db-487e-be30-80e0b794f57d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+01, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+01, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+00, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e+01, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.452e+01, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+02, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+02, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+02, tolerance: 1.536e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.602e+00, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.174e+00, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.595e+00, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+01, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+01, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+02, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.456e+02, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.047e+02, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e+02, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.226e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.466e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.896e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e+03, tolerance: 4.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+01, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+01, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+01, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.864e+01, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.601e+02, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e+02, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e+02, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.738e+02, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.469e+02, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+03, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+03, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.297e+02, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+03, tolerance: 5.413e+00\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alpha* = 0.0004641588833612782\n",
            "Number of nonzero coefficients: 63\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.387e+04, tolerance: 3.011e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -----------------------------\n",
        "# 4. Time-series LASSO with modest CV (to save RAM)\n",
        "# -----------------------------\n",
        "tscv = TimeSeriesSplit(n_splits=3)  # fewer splits = less memory and time\n",
        "lasso_ts = LassoCV(\n",
        "    alphas=np.logspace(-5, 0, 100),\n",
        "    cv=tscv,\n",
        "    max_iter=5000,\n",
        "    n_jobs=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lasso_ts.fit(X_train, y_train)\n",
        "print(\"alpha* =\", lasso_ts.alpha_)\n",
        "print(\"Number of nonzero coefficients:\", np.sum(lasso_ts.coef_ != 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042ef28a-cbe3-4a59-a821-9b25cb8a3cd1",
      "metadata": {
        "id": "042ef28a-cbe3-4a59-a821-9b25cb8a3cd1",
        "outputId": "712bc089-fa22-4155-e5e3-d98f8b87ddf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "be_me                       0.80156\n",
            "GS1                         0.94956\n",
            "GS5                        -1.34766\n",
            "GS30                        0.39509\n",
            "BAA                         0.28318\n",
            "UNRATE                     -0.17074\n",
            "ICSA                        0.01629\n",
            "FEDFUNDS                   -0.15521\n",
            "VIX                        -0.11631\n",
            "OIL                         0.02209\n",
            "TCU                         0.02081\n",
            "RPI                        -0.04473\n",
            "PAYEMS                      0.04417\n",
            "term_spread                 0.11816\n",
            "def_spread                  0.03047\n",
            "inflation                   0.08024\n",
            "core_inflation             -0.02217\n",
            "real_ff                    -0.03189\n",
            "m2_growth                  -0.00834\n",
            "indpro_growth               0.07275\n",
            "rpi_growth                 -0.01876\n",
            "payems_growth              -0.04783\n",
            "oil_ret                    -0.00064\n",
            "me_x_UNRATE                 0.00457\n",
            "me_x_M2                     0.00420\n",
            "me_x_FEDFUNDS              -0.00316\n",
            "me_x_VIX                    0.01003\n",
            "me_x_def_spread            -0.00744\n",
            "me_x_inflation             -0.01003\n",
            "me_x_indpro_growth         -0.00276\n",
            "me_x_rpi_growth             0.00135\n",
            "me_x_payems_growth          0.00431\n",
            "be_me_x_TB3MS               1.47805\n",
            "be_me_x_GS1                -5.86165\n",
            "be_me_x_GS5                 10.88417\n",
            "be_me_x_GS10               -2.85943\n",
            "be_me_x_GS30               -2.84651\n",
            "be_me_x_BAA                -4.61046\n",
            "be_me_x_AAA                -1.18827\n",
            "be_me_x_UNRATE              4.30425\n",
            "be_me_x_M2                  1.90128\n",
            "be_me_x_FEDFUNDS            0.69957\n",
            "be_me_x_VIX                 2.12858\n",
            "be_me_x_OIL                -0.40073\n",
            "be_me_x_INDPRO              3.36508\n",
            "be_me_x_RPI                -2.95915\n",
            "be_me_x_PAYEMS             -1.02486\n",
            "be_me_x_CPI                -0.25661\n",
            "be_me_x_CPICORE            -0.47690\n",
            "be_me_x_term_spread        -1.09515\n",
            "be_me_x_def_spread         -0.31078\n",
            "be_me_x_inflation          -1.01786\n",
            "be_me_x_core_inflation      0.11676\n",
            "be_me_x_m2_growth           0.05693\n",
            "be_me_x_indpro_growth      -0.51687\n",
            "be_me_x_rpi_growth          0.16150\n",
            "be_me_x_payems_growth       0.35336\n",
            "ret_3_1_x_GS1               0.01630\n",
            "ret_3_1_x_GS5               0.00184\n",
            "ret_3_1_x_VIX               0.02918\n",
            "ret_3_1_x_term_spread       0.08824\n",
            "ret_3_1_x_inflation        -0.10901\n",
            "ret_3_1_x_oil_ret          -0.03092\n"
          ]
        }
      ],
      "source": [
        "coefs = lasso_ts.coef_\n",
        "nonzero = [(name, coef) for name, coef in zip(scale_cols, coefs) if coef != 0]\n",
        "for name, coef in nonzero:\n",
        "    print(f\"{name:25s}  {coef: .5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d70317-68b7-4715-be21-b249eba9a4b0",
      "metadata": {
        "id": "01d70317-68b7-4715-be21-b249eba9a4b0",
        "outputId": "d66e4089-289b-4a55-e8bc-96972167e1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alpha* = 0.0044040077361278615\n",
            "largest alpha in grid = 1.0\n",
            "smallest alpha in grid = 1e-05\n"
          ]
        }
      ],
      "source": [
        "print(\"alpha* =\", enet.alpha_)\n",
        "print(\"largest alpha in grid =\", lasso_ts.alphas_[0])\n",
        "print(\"smallest alpha in grid =\", lasso_ts.alphas_[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ab2d28-4c5a-489c-9c32-74418550f25f",
      "metadata": {
        "id": "d1ab2d28-4c5a-489c-9c32-74418550f25f",
        "outputId": "f1b48085-5e46-45c8-e9dc-0155436cd8b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test IC: 0.01973286167808728\n",
            "Test MSE: 20.50855\n",
            "Test R^2: -289.23211669921875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\yimengs\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.387e+04, tolerance: 3.011e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "lasso_final = Lasso(alpha=lasso_ts.alpha_, max_iter=5000)\n",
        "lasso_final.fit(X_train, y_train)\n",
        "\n",
        "y_pred_test = lasso_final.predict(X_test)\n",
        "\n",
        "ic_test  = np.corrcoef(y_test, y_pred_test)[0, 1]\n",
        "mse_test = np.mean((y_test - y_pred_test)**2)\n",
        "r2_test  = 1 - mse_test / np.var(y_test)\n",
        "\n",
        "print(\"Test IC:\", ic_test)\n",
        "print(\"Test MSE:\", mse_test)\n",
        "print(\"Test R^2:\", r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "91817149-9b1e-4e2a-bc06-33484f599f7b",
      "metadata": {
        "id": "91817149-9b1e-4e2a-bc06-33484f599f7b"
      },
      "outputs": [],
      "source": [
        "survival_factors = [\n",
        "    \"be_me\",\n",
        "    \"GS1\",\n",
        "    \"GS5\",\n",
        "    \"GS30\",\n",
        "    \"BAA\",\n",
        "    \"UNRATE\",\n",
        "    \"ICSA\",\n",
        "    \"FEDFUNDS\",\n",
        "    \"VIX\",\n",
        "    \"OIL\",\n",
        "    \"TCU\",\n",
        "    \"RPI\",\n",
        "    \"PAYEMS\",\n",
        "    \"term_spread\",\n",
        "    \"def_spread\",\n",
        "    \"inflation\",\n",
        "    \"core_inflation\",\n",
        "    \"real_ff\",\n",
        "    \"m2_growth\",\n",
        "    \"indpro_growth\",\n",
        "    \"rpi_growth\",\n",
        "    \"payems_growth\",\n",
        "    \"oil_ret\",\n",
        "    \"me_x_UNRATE\",\n",
        "    \"me_x_M2\",\n",
        "    \"me_x_FEDFUNDS\",\n",
        "    \"me_x_VIX\",\n",
        "    \"me_x_def_spread\",\n",
        "    \"me_x_inflation\",\n",
        "    \"me_x_indpro_growth\",\n",
        "    \"me_x_rpi_growth\",\n",
        "    \"me_x_payems_growth\",\n",
        "    \"be_me_x_TB3MS\",\n",
        "    \"be_me_x_GS1\",\n",
        "    \"be_me_x_GS5\",\n",
        "    \"be_me_x_GS10\",\n",
        "    \"be_me_x_GS30\",\n",
        "    \"be_me_x_BAA\",\n",
        "    \"be_me_x_AAA\",\n",
        "    \"be_me_x_UNRATE\",\n",
        "    \"be_me_x_M2\",\n",
        "    \"be_me_x_FEDFUNDS\",\n",
        "    \"be_me_x_VIX\",\n",
        "    \"be_me_x_OIL\",\n",
        "    \"be_me_x_INDPRO\",\n",
        "    \"be_me_x_RPI\",\n",
        "    \"be_me_x_PAYEMS\",\n",
        "    \"be_me_x_CPI\",\n",
        "    \"be_me_x_CPICORE\",\n",
        "    \"be_me_x_term_spread\",\n",
        "    \"be_me_x_def_spread\",\n",
        "    \"be_me_x_inflation\",\n",
        "    \"be_me_x_core_inflation\",\n",
        "    \"be_me_x_m2_growth\",\n",
        "    \"be_me_x_indpro_growth\",\n",
        "    \"be_me_x_rpi_growth\",\n",
        "    \"be_me_x_payems_growth\",\n",
        "    \"ret_3_1_x_GS1\",\n",
        "    \"ret_3_1_x_GS5\",\n",
        "    \"ret_3_1_x_VIX\",\n",
        "    \"ret_3_1_x_term_spread\",\n",
        "    \"ret_3_1_x_inflation\",\n",
        "    \"ret_3_1_x_oil_ret\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keep_cols = [\"eom\", \"ret_exc_lead1m\"] + survival_factors\n",
        "data_reduced = data[keep_cols]\n"
      ],
      "metadata": {
        "id": "nbfigOCIK3cN"
      },
      "id": "nbfigOCIK3cN",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_reduced.to_csv(\"survival_data.csv.gz\", index=False, compression=\"gzip\")\n"
      ],
      "metadata": {
        "id": "VNMIiPg6Lh5K"
      },
      "id": "VNMIiPg6Lh5K",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}